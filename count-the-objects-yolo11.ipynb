{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EM2nwU4jshF"
      },
      "source": [
        "# Object Counting using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for [counting objects](https://docs.ultralytics.com/guides/object-counting/) in videos or live streams using the YOLO11 model.\n",
        "\n",
        "### What is Object Counting?\n",
        "\n",
        "- Object counting with YOLO11 involves accurate identification and counting of specific objects in videos and camera streams. YOLO11 excels in real-time applications, providing efficient and precise object counting for various scenarios like crowd analysis and surveillance, thanks to its state-of-the-art algorithms and deep learning capabilities.\n",
        "\n",
        "### Advantages of Object Counting?\n",
        "\n",
        "- **Resource Optimization**: Object counting facilitates efficient resource management by providing accurate counts, and optimizing resource allocation in applications like inventory management.\n",
        "- **Enhanced Security**: Object counting enhances security and surveillance by accurately tracking and counting entities, aiding in proactive threat detection.\n",
        "- **Informed Decision-Making**: Object counting offers valuable insights for decision-making, optimizing processes in retail, traffic management, and various other domains."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.192  Python-3.13.1 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
            "Setup complete  (32 CPUs, 31.6 GB RAM, 29.2/195.3 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!uv pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "import cv2\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "from ultralytics import solutions\n",
        "\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8go3HNgN0WU"
      },
      "source": [
        "### Read the Video File\n",
        "\n",
        "- You can either read the video file directly or stream the content from an RTSP (Real-Time Streaming Protocol) source, allowing for flexible video input depending on your needs.\n",
        "- We will also set up the video writer to handle the output video writing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QUgMYUvlNLvy"
      },
      "outputs": [],
      "source": [
        "safe_download(\"https://github.com/ultralytics/notebooks/releases/download/v0.0.0/solutions-ci-demo.mp4\")\n",
        "cap = cv2.VideoCapture(\"solutions-ci-demo.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH,\n",
        "                                       cv2.CAP_PROP_FRAME_HEIGHT,\n",
        "                                       cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"counting.avi\",\n",
        "                               cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "                               fps, (w, h))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wJlBXORXNsj"
      },
      "source": [
        "### Define Region Coordinates\n",
        "\n",
        "Here, we set the coordinates for specific regions to ensure accurate object tracking and analysis within the video or stream. This helps monitor and count objects effectively in different areas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bVCrrForXRgS"
      },
      "outputs": [],
      "source": [
        "# Define region points\n",
        "# region_points = [(20, 400), (1080, 400)]  # For line counting\n",
        "region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]  # For rectangle region counting\n",
        "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]  # For polygon region counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3soEHzXe8c"
      },
      "source": [
        "### Initialize the ObjectCounter Class\n",
        "\n",
        "- Now, let's initialize the `ObjectCounter` class to track and count objects in each frame of the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Va24DpUZXTh3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics Solutions:  {'source': None, 'model': 'yolo11n.pt', 'classes': None, 'show_conf': True, 'show_labels': True, 'region': [(20, 400), (1080, 400), (1080, 360), (20, 360)], 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n"
          ]
        }
      ],
      "source": [
        "# Init ObjectCounter\n",
        "counter = solutions.ObjectCounter(\n",
        "    show=True,  # Display the output\n",
        "    region=region_points,  # Pass region points\n",
        "    model=\"yolo11n.pt\",  # model=\"yolo11n-obb.pt\" for object counting using YOLO11 OBB model.\n",
        "    # classes=[0, 2],  # If you want to count specific classes i.e person and car with COCO pretrained model.\n",
        "    # show_in=True,  # Display in counts\n",
        "    # show_out=True,  # Display out counts\n",
        "    # line_width=2,  # Adjust the line width for bounding boxes and text display\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ewYRFFqXvtj"
      },
      "source": [
        "### Process Video Frames\n",
        "\n",
        "In this step, we will process each frame of the video to detect and analyze objects. This allows for real-time tracking and counting, based on the visual data in the frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVf1pyRtXijz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 360x640 31.2ms, 21 person\n",
            "Speed: 696.7ms track, 31.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "1: 360x640 18.1ms, 21 person\n",
            "Speed: 24.2ms track, 18.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "2: 360x640 10.9ms, 14 person\n",
            "Speed: 33.2ms track, 10.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "3: 360x640 7.3ms, 14 person\n",
            "Speed: 20.8ms track, 7.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "4: 360x640 6.2ms, 15 person\n",
            "Speed: 22.3ms track, 6.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "5: 360x640 6.0ms, 16 person\n",
            "Speed: 22.4ms track, 6.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "6: 360x640 18.5ms, 16 person\n",
            "Speed: 23.9ms track, 18.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "7: 360x640 5.6ms, 16 person\n",
            "Speed: 21.6ms track, 5.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "8: 360x640 13.3ms, 16 person\n",
            "Speed: 30.2ms track, 13.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "9: 360x640 15.9ms, 18 person\n",
            "Speed: 28.1ms track, 15.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "10: 360x640 10.5ms, 17 person\n",
            "Speed: 18.8ms track, 10.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "11: 360x640 4.1ms, 17 person\n",
            "Speed: 23.3ms track, 4.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "12: 360x640 3.9ms, 17 person\n",
            "Speed: 24.4ms track, 3.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "13: 360x640 7.1ms, 17 person\n",
            "Speed: 21.4ms track, 7.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "14: 360x640 6.6ms, 16 person\n",
            "Speed: 21.6ms track, 6.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "15: 360x640 9.6ms, 16 person\n",
            "Speed: 18.7ms track, 9.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "16: 360x640 9.5ms, 16 person\n",
            "Speed: 18.9ms track, 9.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "17: 360x640 10.4ms, 15 person\n",
            "Speed: 17.8ms track, 10.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "18: 360x640 19.8ms, 16 person\n",
            "Speed: 25.6ms track, 19.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "19: 360x640 4.5ms, 16 person\n",
            "Speed: 22.5ms track, 4.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "20: 360x640 3.9ms, 16 person\n",
            "Speed: 23.5ms track, 3.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "21: 360x640 6.1ms, 15 person\n",
            "Speed: 22.8ms track, 6.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "22: 360x640 6.4ms, 15 person\n",
            "Speed: 22.1ms track, 6.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "23: 360x640 5.8ms, 15 person\n",
            "Speed: 22.7ms track, 5.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "24: 360x640 7.1ms, 15 person\n",
            "Speed: 21.8ms track, 7.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "25: 360x640 7.5ms, 15 person\n",
            "Speed: 21.2ms track, 7.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "26: 360x640 17.7ms, 14 person\n",
            "Speed: 25.9ms track, 17.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "27: 360x640 5.7ms, 17 person\n",
            "Speed: 22.9ms track, 5.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "28: 360x640 7.3ms, 17 person\n",
            "Speed: 22.2ms track, 7.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "29: 360x640 7.6ms, 17 person\n",
            "Speed: 21.0ms track, 7.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "30: 360x640 8.1ms, 17 person\n",
            "Speed: 21.0ms track, 8.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "31: 360x640 5.2ms, 17 person\n",
            "Speed: 21.4ms track, 5.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "32: 360x640 3.4ms, 17 person\n",
            "Speed: 22.3ms track, 3.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "33: 360x640 13.5ms, 16 person\n",
            "Speed: 32.0ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "34: 360x640 6.0ms, 18 person\n",
            "Speed: 22.6ms track, 6.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "35: 360x640 6.5ms, 17 person\n",
            "Speed: 38.1ms track, 6.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "36: 360x640 7.2ms, 17 person\n",
            "Speed: 21.4ms track, 7.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "37: 360x640 7.6ms, 17 person\n",
            "Speed: 20.8ms track, 7.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "38: 360x640 7.7ms, 17 person\n",
            "Speed: 21.3ms track, 7.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "39: 360x640 7.6ms, 17 person\n",
            "Speed: 21.6ms track, 7.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "40: 360x640 4.9ms, 16 person\n",
            "Speed: 23.3ms track, 4.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "41: 360x640 5.5ms, 16 person\n",
            "Speed: 21.6ms track, 5.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "42: 360x640 9.0ms, 16 person\n",
            "Speed: 19.5ms track, 9.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "43: 360x640 7.9ms, 16 person\n",
            "Speed: 20.4ms track, 7.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "44: 360x640 10.2ms, 16 person\n",
            "Speed: 18.8ms track, 10.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "45: 360x640 9.8ms, 16 person\n",
            "Speed: 19.3ms track, 9.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "46: 360x640 6.3ms, 16 person\n",
            "Speed: 23.0ms track, 6.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "47: 360x640 8.8ms, 17 person\n",
            "Speed: 19.8ms track, 8.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "48: 360x640 7.4ms, 15 person\n",
            "Speed: 20.7ms track, 7.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "49: 360x640 10.2ms, 15 person\n",
            "Speed: 18.6ms track, 10.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "50: 360x640 8.5ms, 15 person\n",
            "Speed: 19.5ms track, 8.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "51: 360x640 7.2ms, 17 person\n",
            "Speed: 21.8ms track, 7.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "52: 360x640 4.5ms, 18 person\n",
            "Speed: 25.6ms track, 4.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "53: 360x640 18.3ms, 21 person\n",
            "Speed: 26.4ms track, 18.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "54: 360x640 5.1ms, 21 person\n",
            "Speed: 23.4ms track, 5.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "55: 360x640 8.5ms, 21 person\n",
            "Speed: 20.9ms track, 8.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "56: 360x640 18.0ms, 19 person\n",
            "Speed: 25.4ms track, 18.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "57: 360x640 6.1ms, 19 person\n",
            "Speed: 22.1ms track, 6.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "58: 360x640 7.1ms, 21 person\n",
            "Speed: 21.9ms track, 7.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "59: 360x640 7.1ms, 21 person\n",
            "Speed: 21.7ms track, 7.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "60: 360x640 4.7ms, 21 person\n",
            "Speed: 25.0ms track, 4.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "61: 360x640 8.4ms, 21 person\n",
            "Speed: 20.6ms track, 8.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "    results = counter(im0)  # count the objects\n",
        "    video_writer.write(results.plot_im)   # write the video frames\n",
        "\n",
        "cap.release()   # Release the capture\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWskbLSKH2S5"
      },
      "source": [
        "![Fish Counting in the Sea Using Ultralytics YOLO11](https://github.com/ultralytics/docs/releases/download/0/conveyor-belt-packets-counting.avif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBUa5kZyZ2k"
      },
      "source": [
        "Crafted with ðŸ’™ by [Ultralytics](https://ultralytics.com/)  \n",
        "\n",
        "ðŸŒŸ Explore and star the [Ultralytics Notebooks](https://github.com/ultralytics/notebooks/) to supercharge your AI journey! ðŸš€"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
