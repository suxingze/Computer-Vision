{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EM2nwU4jshF"
      },
      "source": [
        "# TrackZone using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for [tracking objects in zones](https://docs.ultralytics.com/guides/trackzone/) in videos or live streams using the YOLO11 model.\n",
        "\n",
        "### What is TrackZone?\n",
        "\n",
        "TrackZone specializes in monitoring objects within designated areas of a frame instead of the whole frame. Built on [Ultralytics YOLO11](https://github.com/ultralytics/ultralytics/), it integrates object detection and tracking specifically within zones for videos and live camera feeds. YOLO11's advanced algorithms and [deep learning](https://www.ultralytics.com/glossary/deep-learning-dl) technologies make it a perfect choice for real-time use cases, offering precise and efficient object tracking in applications like crowd monitoring and surveillance.\n",
        "\n",
        "### Advantages of Object Tracking in Zones (TrackZone)\n",
        "\n",
        "- **Targeted Analysis:** Tracking objects within specific zones allows for more focused insights, enabling precise monitoring and analysis of areas of interest, such as entry points or restricted zones.\n",
        "- **Improved Efficiency:** By narrowing the tracking scope to defined zones, TrackZone reduces computational overhead, ensuring faster processing and optimal performance.\n",
        "- **Enhanced Security:** Zonal tracking improves surveillance by monitoring critical areas, aiding in the early detection of unusual activity or security breaches.\n",
        "- **Scalable Solutions:** The ability to focus on specific zones makes TrackZone adaptable to various scenarios, from retail spaces to industrial settings, ensuring seamless integration and scalability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://clickpy.clickhouse.com/dashboard/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.192  Python-3.13.1 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
            "Setup complete  (32 CPUs, 31.6 GB RAM, 30.7/195.3 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!uv pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "import cv2\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "from ultralytics import solutions\n",
        "\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8go3HNgN0WU"
      },
      "source": [
        "### Read the Video File\n",
        "\n",
        "- You can either read the video file directly or stream the content from an RTSP (Real-Time Streaming Protocol) source, allowing for flexible video input depending on your needs.\n",
        "- We will also set up the video writer to handle the output video writing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QUgMYUvlNLvy"
      },
      "outputs": [],
      "source": [
        "safe_download(\"https://github.com/ultralytics/notebooks/releases/download/v0.0.0/solutions-ci-demo.mp4\")\n",
        "cap = cv2.VideoCapture(\"solutions-ci-demo.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH,\n",
        "                                       cv2.CAP_PROP_FRAME_HEIGHT,\n",
        "                                       cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"trackzone.avi\",\n",
        "                               cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "                               fps, (w, h))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wJlBXORXNsj"
      },
      "source": [
        "### Define Region Coordinates\n",
        "\n",
        "Here, we set the coordinates for specific regions to ensure accurate object tracking and analysis within the video or stream. This helps monitor and track objects effectively in different areas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bVCrrForXRgS"
      },
      "outputs": [],
      "source": [
        "# Define region points\n",
        "# region_points = [(20, 400), (1080, 400)]  # For line tracking\n",
        "region_points = [(w/2, 0), (w, 0), (w/2, h), (0, h)]  # For rectangle region tracking\n",
        "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]  # For polygon region tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt3soEHzXe8c"
      },
      "source": [
        "### Initialize the TrackZone Class\n",
        "\n",
        "- Next, let's initialize the `TrackZone` class to track objects in each frame of the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Va24DpUZXTh3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics Solutions:  {'source': None, 'model': 'yolo11n.pt', 'classes': None, 'show_conf': True, 'show_labels': True, 'region': [(320.0, 0), (640, 0), (320.0, 360), (0, 360)], 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n"
          ]
        }
      ],
      "source": [
        " # Init TrackZone (Object Tracking in Zones, not complete frame)\n",
        "trackzone = solutions.TrackZone(\n",
        "    show=True,  # Display the output\n",
        "    region=region_points,  # Pass region points\n",
        "    model=\"yolo11n.pt\",  # You can use any model that Ultralytics support, i.e. YOLOv9, YOLOv10\n",
        "    # line_width=2,  # Adjust the line width for bounding boxes and text display\n",
        "    # classes=[0, 2],  # If you want to track specific classes i.e. person and car with COCO pretrained model.\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ewYRFFqXvtj"
      },
      "source": [
        "### Process Video Frames\n",
        "\n",
        "In this step, we will process each frame of the video to detect and analyze objects. This allows for real-time tracking, based on the visual data in the frames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PVf1pyRtXijz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 360x640 32.7ms, 11 person\n",
            "Speed: 547.3ms track, 32.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "1: 360x640 14.6ms, 11 person\n",
            "Speed: 28.1ms track, 14.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "2: 360x640 8.4ms, 11 person\n",
            "Speed: 19.7ms track, 8.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "3: 360x640 10.1ms, 11 person\n",
            "Speed: 18.5ms track, 10.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "4: 360x640 10.4ms, 11 person\n",
            "Speed: 17.4ms track, 10.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "5: 360x640 11.1ms, 1 bird, 10 person\n",
            "Speed: 18.0ms track, 11.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "6: 360x640 11.6ms, 9 person\n",
            "Speed: 17.2ms track, 11.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "7: 360x640 11.6ms, 9 person\n",
            "Speed: 17.0ms track, 11.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "8: 360x640 11.5ms, 10 person\n",
            "Speed: 17.9ms track, 11.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "9: 360x640 12.8ms, 9 person\n",
            "Speed: 16.1ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "10: 360x640 11.7ms, 9 person\n",
            "Speed: 17.3ms track, 11.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "11: 360x640 13.4ms, 9 person\n",
            "Speed: 15.9ms track, 13.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "12: 360x640 11.4ms, 9 person\n",
            "Speed: 16.1ms track, 11.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "13: 360x640 14.3ms, 10 person\n",
            "Speed: 14.7ms track, 14.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "14: 360x640 13.5ms, 10 person\n",
            "Speed: 15.5ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "15: 360x640 11.4ms, 11 person\n",
            "Speed: 17.9ms track, 11.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "16: 360x640 13.8ms, 11 person\n",
            "Speed: 15.7ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "17: 360x640 11.9ms, 11 person\n",
            "Speed: 16.0ms track, 11.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "18: 360x640 14.0ms, 11 person\n",
            "Speed: 15.7ms track, 14.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "19: 360x640 13.4ms, 11 person\n",
            "Speed: 15.8ms track, 13.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "20: 360x640 14.0ms, 10 person\n",
            "Speed: 15.4ms track, 14.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "21: 360x640 6.2ms, 11 person\n",
            "Speed: 21.0ms track, 6.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "22: 360x640 11.3ms, 11 person\n",
            "Speed: 16.4ms track, 11.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "23: 360x640 13.6ms, 11 person\n",
            "Speed: 15.8ms track, 13.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "24: 360x640 11.8ms, 11 person\n",
            "Speed: 17.6ms track, 11.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "25: 360x640 14.1ms, 11 person\n",
            "Speed: 15.4ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "26: 360x640 11.3ms, 10 person\n",
            "Speed: 18.5ms track, 11.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "27: 360x640 9.7ms, 8 person\n",
            "Speed: 18.4ms track, 9.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "28: 360x640 13.9ms, 8 person\n",
            "Speed: 14.4ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "29: 360x640 16.2ms, 7 person\n",
            "Speed: 13.1ms track, 16.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "30: 360x640 14.9ms, 7 person\n",
            "Speed: 13.4ms track, 14.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "31: 360x640 13.9ms, 7 person\n",
            "Speed: 15.3ms track, 13.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "32: 360x640 15.5ms, 8 person\n",
            "Speed: 14.1ms track, 15.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "33: 360x640 12.6ms, 7 person\n",
            "Speed: 15.3ms track, 12.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "34: 360x640 14.6ms, 8 person\n",
            "Speed: 14.2ms track, 14.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "35: 360x640 14.7ms, 9 person\n",
            "Speed: 14.1ms track, 14.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "36: 360x640 15.2ms, 9 person\n",
            "Speed: 14.3ms track, 15.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "37: 360x640 14.9ms, 9 person\n",
            "Speed: 14.1ms track, 14.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "38: 360x640 13.7ms, 6 person\n",
            "Speed: 15.4ms track, 13.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "39: 360x640 15.0ms, 8 person\n",
            "Speed: 14.1ms track, 15.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "40: 360x640 15.1ms, 8 person\n",
            "Speed: 13.5ms track, 15.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "41: 360x640 15.4ms, 7 person\n",
            "Speed: 12.9ms track, 15.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "42: 360x640 15.7ms, 7 person\n",
            "Speed: 13.4ms track, 15.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "43: 360x640 15.2ms, 7 person\n",
            "Speed: 13.8ms track, 15.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "44: 360x640 16.1ms, 8 person\n",
            "Speed: 13.9ms track, 16.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "45: 360x640 14.7ms, 8 person\n",
            "Speed: 14.6ms track, 14.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "46: 360x640 14.6ms, 12 person\n",
            "Speed: 15.0ms track, 14.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "47: 360x640 13.0ms, 12 person\n",
            "Speed: 16.1ms track, 13.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "48: 360x640 14.4ms, 11 person\n",
            "Speed: 14.5ms track, 14.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "49: 360x640 14.3ms, 11 person\n",
            "Speed: 15.1ms track, 14.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "50: 360x640 15.2ms, 10 person\n",
            "Speed: 14.9ms track, 15.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "51: 360x640 12.8ms, 10 person\n",
            "Speed: 15.6ms track, 12.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "52: 360x640 13.8ms, 11 person\n",
            "Speed: 14.6ms track, 13.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "53: 360x640 10.9ms, 11 person\n",
            "Speed: 17.2ms track, 10.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "54: 360x640 13.5ms, 11 person\n",
            "Speed: 15.5ms track, 13.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "55: 360x640 14.0ms, 11 person\n",
            "Speed: 15.2ms track, 14.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "56: 360x640 11.5ms, 11 person\n",
            "Speed: 16.9ms track, 11.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "57: 360x640 12.3ms, 11 person\n",
            "Speed: 17.5ms track, 12.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "58: 360x640 14.1ms, 11 person\n",
            "Speed: 16.2ms track, 14.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "59: 360x640 14.6ms, 10 person\n",
            "Speed: 14.5ms track, 14.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "60: 360x640 7.8ms, 10 person\n",
            "Speed: 20.1ms track, 7.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "61: 360x640 14.7ms, 12 person\n",
            "Speed: 15.1ms track, 14.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        }
      ],
      "source": [
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "    results = trackzone(im0)  # track the objects\n",
        "    video_writer.write(results.plot_im)   # write the video frames\n",
        "\n",
        "cap.release()   # Release the capture\n",
        "video_writer.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWskbLSKH2S5"
      },
      "source": [
        "![Plants Tracking in Field Using Ultralytics YOLO11](https://github.com/ultralytics/docs/releases/download/0/plants-tracking-in-zone-using-ultralytics-yolo11.avif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBUa5kZyZ2k"
      },
      "source": [
        "Crafted with ðŸ’™ by [Ultralytics](https://ultralytics.com/)  \n",
        "\n",
        "ðŸŒŸ Explore and star the [Ultralytics Notebooks](https://github.com/ultralytics/notebooks/) to supercharge your AI journey! ðŸš€"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
